{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from oci.config import from_file\n",
    "from oci.generative_ai import GenerativeAiClient\n",
    "from oci.generative_ai_inference import GenerativeAiInferenceClient\n",
    "from oci.generative_ai_inference.models import (\n",
    "    EmbedTextDetails,\n",
    "    OnDemandServingMode,\n",
    "    GenerateTextDetails,\n",
    "    CohereLlmInferenceRequest,\n",
    "    SummarizeTextDetails\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "config = from_file()\n",
    "\n",
    "GEN_AI_ENDPOINT = os.getenv('GEN_AI_ENDPOINT')\n",
    "GEN_AI_INFERENCE_ENDPOINT = os.getenv('GEN_AI_INFERENCE_ENDPOINT')\n",
    "COMPARTMENT_ID = os.getenv('COMPARTMENT_ID')\n",
    "gen_ai_client = GenerativeAiClient(config=config, service_endpoint=GEN_AI_ENDPOINT)\n",
    "gen_ai_inference_client = GenerativeAiInferenceClient(config=config, service_endpoint=GEN_AI_INFERENCE_ENDPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative AI - Manage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists the models in a specific compartment\n",
    "list_models_response = gen_ai_client.list_models(compartment_id=COMPARTMENT_ID)\n",
    "list_models_response.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative AI - Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_MODEL_OCID = os.getenv('EMBEDDINGS_MODEL_OCID')\n",
    "SUMMARIZE_MODEL_OCID = os.getenv('SUMMARIZE_MODEL_OCID')\n",
    "GENERATION_MODEL_OCID = os.getenv('GENERATION_MODEL_OCID')\n",
    "\n",
    "print(f\"embeddings: {EMBEDDINGS_MODEL_OCID}\")\n",
    "print(f\"summatize: {SUMMARIZE_MODEL_OCID}\")\n",
    "print(f\"generation: {GENERATION_MODEL_OCID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    \"Learn about the Employee Stock Purchase Plan\",\n",
    "    \"Reassign timecard approvals during leave\",\n",
    "    \"View my payslip online\",\n",
    "    \"Learn about the Employee Stock Purchase Plan\",\n",
    "    \"Reassign timecard approvals during leave\",\n",
    "    \"View my payslip online\",\n",
    "    \"Enroll in benefits\",\n",
    "    \"Change my direct deposit\",\n",
    "    \"Have my employment/income verified\",\n",
    "    \"Request A Workplace Accommodation\",\n",
    "    \"Submit my time card\",\n",
    "    \"Report Information Security Incidents\",\n",
    "    \"Review the Code of Conduct\",\n",
    "    \"Review the Social Media Policy\",\n",
    "    \"Review Corporate Information Security Policies\",\n",
    "    \"Understand Compliance and Ethics\",\n",
    "    \"Understand the Fiscal Year Calendar\",\n",
    "    \"Change my email address\",\n",
    "    \"Change my personal information\",\n",
    "    \"Learn about Analyst Relations\",\n",
    "    \"Learn about Business Skills\",\n",
    "    \"Learn about Career Development\",\n",
    "    \"Learn about Employee Resource Groups\",\n",
    "    \"Learn about Information Security\",\n",
    "    \"Learn about Leadership skills\",\n",
    "    \"Learn about sustainability\",\n",
    "    \"Learn about Technical skills\",\n",
    "    \"Request a Phone Number\",\n",
    "    \"Learn about video conferencing\",\n",
    "    \"Learn about Organizational Distribution Lists\",\n",
    "    \"Subscribe to Group Mailing Lists\",\n",
    "    \"Find a Campus Map\",\n",
    "    \"Obtain a security badge\",\n",
    "    \"Obtain an office workspace\",\n",
    "    \"Submit an ergonomics request\",\n",
    "    \"Use printers\",\n",
    "    \"Delegate workflows or transaction approvals while out on leave\",\n",
    "    \"Tips for working remotely\",\n",
    "    \"Volunteer\",\n",
    "    \"Reassign workflow approvals while on vacation\",\n",
    "    \"How to delegate timecard approvals\",\n",
    "    \"Apply for Corporate Credit Card\",\n",
    "    \"Book travel\",\n",
    "    \"Submit an expense report\"\n",
    "]\n",
    "\n",
    "embed_text_result = gen_ai_inference_client.embed_text(\n",
    "    embed_text_details=EmbedTextDetails(\n",
    "        inputs=inputs,\n",
    "        serving_mode=OnDemandServingMode(model_id=EMBEDDINGS_MODEL_OCID),\n",
    "        compartment_id=COMPARTMENT_ID,\n",
    "        is_echo=True,\n",
    "        truncate='NONE',\n",
    "    )\n",
    ")\n",
    "\n",
    "embed_text_result.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Generate a job description for a data visualization expert with the following three qualifications only:\n",
    "1) At least 5 years of data visualization expert\n",
    "2) A great eye for details\n",
    "3) Ability to create original visualizations\n",
    "\"\"\"\n",
    "\n",
    "generate_text_response = gen_ai_inference_client.generate_text(\n",
    "    generate_text_details=GenerateTextDetails(\n",
    "        compartment_id=COMPARTMENT_ID,\n",
    "        serving_mode=OnDemandServingMode(\n",
    "            model_id=GENERATION_MODEL_OCID\n",
    "        ),\n",
    "        inference_request=CohereLlmInferenceRequest(\n",
    "            prompt=prompt,\n",
    "            is_stream=False,\n",
    "            num_generations=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "generate_text_response.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"\"\"\n",
    "Oracle’s strategy is built around the reality that enterprises work with AI through three different modalities: Infrastructure, models and services, and within applications.\n",
    "\n",
    "First, we provide a robust infrastructure for training and serving models at scale. Through our partnership with NVIDIA, we can give customers superclusters, which are powered by the latest GPUs in the market connected together with an ultra-low-latency RDMA over converged ethernet (RoCE) network. This solution provides a highly performant, cost-effective method for training generative AI models at scale. Many AI startups like Adept and MosaicML are building their products directly on OCI.\n",
    "\n",
    "Second, we provide easy-to-use cloud services for developers and scientists to utilize in fully managed implementations. We’re enabling new generative AI services and business functions through our partnership with Cohere, a leading generative AI company for enterprise-grade large language models (LLMs). Through our partnership with Cohere, we’re building a new generative AI service. This upcoming AI service, OCI Generative AI, enables OCI customers to add generative AI capabilities to their own applications and workflows through simple APIs.\n",
    "\n",
    "Third, we embed generative models into the applications and workflows that business users use every day. Oracle plans to embed generative AI from Cohere into its Fusion, NetSuite, and our vertical software-as-a-service (SaaS) portfolio to create solutions that provide organizations with the full power of generative AI immediately. Across industries, Oracle can provide native generative AI-based features to help organizations automate key business functions, improve decision-making, and enhance customer experiences. For example, in healthcare, Oracle Cerner manages billions of electronic health records (EHR). Using anonymized data, Oracle can create generative models adapted to the healthcare domain, such as automatically generating a patient discharge summary or a letter of authorization for medical insurance.\n",
    "\n",
    "Oracle’s generative AI offerings span applications to infrastructure and provide the highest levels of security, performance, efficiency, and value.\n",
    "\"\"\"\n",
    "\n",
    "summarize_text_response = gen_ai_inference_client.summarize_text(\n",
    "    summarize_text_details=SummarizeTextDetails(\n",
    "        input=input,\n",
    "        serving_mode=OnDemandServingMode(\n",
    "            model_id=SUMMARIZE_MODEL_OCID\n",
    "        ),\n",
    "        compartment_id=COMPARTMENT_ID,\n",
    "        is_echo=True,\n",
    "        temperature=1.0,\n",
    "        length='SHORT',\n",
    "        format='AUTO',\n",
    "        extractiveness='AUTO'\n",
    "    )\n",
    ")\n",
    "\n",
    "summarize_text_response.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
